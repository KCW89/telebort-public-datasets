{
  "type": "excalidraw",
  "version": 2,
  "source": "https://excalidraw.com",
  "elements": [
    {
      "id": "title-main",
      "type": "text",
      "x": 520,
      "y": 40,
      "width": 800,
      "height": 45,
      "fontSize": 36,
      "fontFamily": 1,
      "text": "AI-2.5 Project 6: Multi-Modal Content Generator",
      "textAlign": "center",
      "verticalAlign": "top",
      "baseline": 32,
      "strokeColor": "#f08c00",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "roughness": 0,
      "opacity": 100,
      "groupIds": []
    },
    {
      "id": "subtitle",
      "type": "text",
      "x": 520,
      "y": 95,
      "width": 800,
      "height": 25,
      "fontSize": 20,
      "fontFamily": 1,
      "text": "CLIP + Stable Diffusion + BLIP-2 + FAISS Integration",
      "textAlign": "center",
      "verticalAlign": "top",
      "baseline": 18,
      "strokeColor": "#ffffff",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": []
    },
    {
      "id": "section1-header",
      "type": "rectangle",
      "x": 50,
      "y": 160,
      "width": 1800,
      "height": 50,
      "strokeColor": "#f08c00",
      "backgroundColor": "#2c2c2c",
      "fillStyle": "solid",
      "strokeWidth": 3,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section1"]
    },
    {
      "id": "section1-title",
      "type": "text",
      "x": 70,
      "y": 172,
      "width": 700,
      "height": 30,
      "fontSize": 24,
      "fontFamily": 1,
      "text": "1Ô∏è‚É£ FILE MAP: Multi-Modal Notebook Structure",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 21,
      "strokeColor": "#f08c00",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section1"]
    },
    {
      "id": "file1",
      "type": "rectangle",
      "x": 70,
      "y": 240,
      "width": 420,
      "height": 360,
      "strokeColor": "#1971c2",
      "backgroundColor": "#1a1a1a",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "roughness": 1,
      "opacity": 100,
      "groupIds": ["section1"]
    },
    {
      "id": "file1-title",
      "type": "text",
      "x": 90,
      "y": 255,
      "width": 380,
      "height": 25,
      "fontSize": 20,
      "fontFamily": 3,
      "text": "üìì project-06-*.ipynb (Main Notebook)",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 18,
      "strokeColor": "#1971c2",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section1"]
    },
    {
      "id": "file1-content",
      "type": "text",
      "x": 90,
      "y": 290,
      "width": 380,
      "height": 295,
      "fontSize": 16,
      "fontFamily": 3,
      "text": "Section 1: Load Models ‚úÖ\n  ‚Ä¢ CLIP (Vision + Text)\n  ‚Ä¢ Stable Diffusion\n  ‚Ä¢ BLIP-2 Captioning\n  ‚Ä¢ Helper functions\n\nSection 2: TODO 1 üî®\n  ‚Ä¢ CLIP-guided generation\n\nSection 3: TODO 2 üî®\n  ‚Ä¢ Beam search captioning\n\nSection 4: TODO 3 üî®\n  ‚Ä¢ Cross-modal retrieval\n  ‚Ä¢ FAISS search\n  ‚Ä¢ Recall@K metrics\n\nSection 5: Integration Test ‚úÖ\nSection 6: TODO 4 üî® (Gradio)\nSection 7: Optimization ‚úÖ\nSection 8: Benchmarking ‚úÖ",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 285,
      "strokeColor": "#ffffff",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section1"]
    },
    {
      "id": "file2",
      "type": "rectangle",
      "x": 520,
      "y": 240,
      "width": 350,
      "height": 200,
      "strokeColor": "#2f9e44",
      "backgroundColor": "#1a1a1a",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "roughness": 1,
      "opacity": 100,
      "groupIds": ["section1"]
    },
    {
      "id": "file2-title",
      "type": "text",
      "x": 540,
      "y": 255,
      "width": 310,
      "height": 25,
      "fontSize": 20,
      "fontFamily": 3,
      "text": "üîß utils.py (Helpers)",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 18,
      "strokeColor": "#2f9e44",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section1"]
    },
    {
      "id": "file2-content",
      "type": "text",
      "x": 540,
      "y": 290,
      "width": 310,
      "height": 135,
      "fontSize": 16,
      "fontFamily": 3,
      "text": "‚Ä¢ encode_image_clip()\n‚Ä¢ encode_text_clip()\n‚Ä¢ compute_similarity()\n‚Ä¢ display_images()\n‚Ä¢ preprocess helpers\n‚Ä¢ FAISS utilities\n‚Ä¢ Normalization (L2)",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 125,
      "strokeColor": "#ffffff",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section1"]
    },
    {
      "id": "file3",
      "type": "rectangle",
      "x": 900,
      "y": 240,
      "width": 350,
      "height": 200,
      "strokeColor": "#9c36b5",
      "backgroundColor": "#1a1a1a",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "roughness": 1,
      "opacity": 100,
      "groupIds": ["section1"]
    },
    {
      "id": "file3-title",
      "type": "text",
      "x": 920,
      "y": 255,
      "width": 310,
      "height": 25,
      "fontSize": 20,
      "fontFamily": 3,
      "text": "üåê app.py (Gradio UI)",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 18,
      "strokeColor": "#9c36b5",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section1"]
    },
    {
      "id": "file3-content",
      "type": "text",
      "x": 920,
      "y": 290,
      "width": 310,
      "height": 135,
      "fontSize": 16,
      "fontFamily": 3,
      "text": "4 Tabs:\n  1. üñºÔ∏è Generate (text‚Üíimage)\n  2. üìù Caption (image‚Üítext)\n  3. üîç Search (retrieval)\n  4. ‚ú® Edit (bonus)\n\nModel caching, callbacks",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 125,
      "strokeColor": "#ffffff",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section1"]
    },
    {
      "id": "file4",
      "type": "rectangle",
      "x": 1280,
      "y": 240,
      "width": 310,
      "height": 140,
      "strokeColor": "#1971c2",
      "backgroundColor": "#1a1a1a",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "roughness": 1,
      "opacity": 100,
      "groupIds": ["section1"]
    },
    {
      "id": "file4-title",
      "type": "text",
      "x": 1300,
      "y": 255,
      "width": 270,
      "height": 25,
      "fontSize": 20,
      "fontFamily": 3,
      "text": "‚öôÔ∏è config.py",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 18,
      "strokeColor": "#1971c2",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section1"]
    },
    {
      "id": "file4-content",
      "type": "text",
      "x": 1300,
      "y": 290,
      "width": 270,
      "height": 75,
      "fontSize": 16,
      "fontFamily": 3,
      "text": "‚Ä¢ Model paths\n‚Ä¢ Hyperparameters\n‚Ä¢ Device settings\n‚Ä¢ Cache directories",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 65,
      "strokeColor": "#ffffff",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section1"]
    },
    {
      "id": "file5",
      "type": "rectangle",
      "x": 1280,
      "y": 410,
      "width": 310,
      "height": 140,
      "strokeColor": "#2f9e44",
      "backgroundColor": "#1a1a1a",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "roughness": 1,
      "opacity": 100,
      "groupIds": ["section1"]
    },
    {
      "id": "file5-title",
      "type": "text",
      "x": 1300,
      "y": 425,
      "width": 270,
      "height": 25,
      "fontSize": 20,
      "fontFamily": 3,
      "text": "üìÑ README.md",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 18,
      "strokeColor": "#2f9e44",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section1"]
    },
    {
      "id": "file5-content",
      "type": "text",
      "x": 1300,
      "y": 460,
      "width": 270,
      "height": 75,
      "fontSize": 16,
      "fontFamily": 3,
      "text": "‚Ä¢ Learning objectives\n‚Ä¢ 4 TODOs explained\n‚Ä¢ Grading rubric\n‚Ä¢ Installation guide",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 65,
      "strokeColor": "#ffffff",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section1"]
    },
    {
      "id": "models-note",
      "type": "rectangle",
      "x": 520,
      "y": 470,
      "width": 730,
      "height": 130,
      "strokeColor": "#e03131",
      "backgroundColor": "#2c2c2c",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "roughness": 1,
      "opacity": 100,
      "groupIds": ["section1"]
    },
    {
      "id": "models-note-text",
      "type": "text",
      "x": 540,
      "y": 485,
      "width": 690,
      "height": 100,
      "fontSize": 16,
      "fontFamily": 1,
      "text": "üöÄ Pre-trained Models (Auto-downloaded on first run):\n  ‚Ä¢ CLIP ViT-B/32: ~600MB (vision-language alignment)\n  ‚Ä¢ Stable Diffusion v1.5: ~4GB (text-to-image generation)\n  ‚Ä¢ BLIP-2 OPT-2.7B: ~2GB (image captioning)\n  ‚Ä¢ Total: ~7GB | Requires: T4 GPU (12GB VRAM), 16GB RAM",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 90,
      "strokeColor": "#ffffff",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section1"]
    },
    {
      "id": "section2-header",
      "type": "rectangle",
      "x": 50,
      "y": 650,
      "width": 1800,
      "height": 50,
      "strokeColor": "#f08c00",
      "backgroundColor": "#2c2c2c",
      "fillStyle": "solid",
      "strokeWidth": 3,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section2"]
    },
    {
      "id": "section2-title",
      "type": "text",
      "x": 70,
      "y": 662,
      "width": 900,
      "height": 30,
      "fontSize": 24,
      "fontFamily": 1,
      "text": "2Ô∏è‚É£ DATA FLOW: Multi-Modal Processing Pipeline",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 21,
      "strokeColor": "#f08c00",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section2"]
    },
    {
      "id": "flow-input",
      "type": "rectangle",
      "x": 70,
      "y": 730,
      "width": 220,
      "height": 100,
      "strokeColor": "#1971c2",
      "backgroundColor": "#1a1a1a",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "roughness": 1,
      "opacity": 100,
      "groupIds": ["section2"]
    },
    {
      "id": "flow-input-text",
      "type": "text",
      "x": 90,
      "y": 755,
      "width": 180,
      "height": 50,
      "fontSize": 18,
      "fontFamily": 1,
      "text": "INPUT\n\"sunset over\nmountains\"",
      "textAlign": "center",
      "verticalAlign": "top",
      "baseline": 43,
      "strokeColor": "#1971c2",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section2"]
    },
    {
      "id": "arrow1",
      "type": "arrow",
      "x": 290,
      "y": 780,
      "width": 70,
      "height": 0,
      "strokeColor": "#f08c00",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 3,
      "roughness": 0,
      "opacity": 100,
      "startArrowhead": null,
      "endArrowhead": "arrow",
      "groupIds": ["section2"],
      "points": [[0, 0], [70, 0]]
    },
    {
      "id": "flow-clip-text",
      "type": "rectangle",
      "x": 360,
      "y": 730,
      "width": 200,
      "height": 100,
      "strokeColor": "#2f9e44",
      "backgroundColor": "#1a1a1a",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "roughness": 1,
      "opacity": 100,
      "groupIds": ["section2"]
    },
    {
      "id": "flow-clip-text-label",
      "type": "text",
      "x": 380,
      "y": 745,
      "width": 160,
      "height": 70,
      "fontSize": 16,
      "fontFamily": 1,
      "text": "CLIP Text\nEncoder\n\n‚Üí 512-dim\nembedding",
      "textAlign": "center",
      "verticalAlign": "top",
      "baseline": 63,
      "strokeColor": "#2f9e44",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section2"]
    },
    {
      "id": "arrow2",
      "type": "arrow",
      "x": 560,
      "y": 780,
      "width": 70,
      "height": 0,
      "strokeColor": "#f08c00",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 3,
      "roughness": 0,
      "opacity": 100,
      "startArrowhead": null,
      "endArrowhead": "arrow",
      "groupIds": ["section2"],
      "points": [[0, 0], [70, 0]]
    },
    {
      "id": "flow-sd",
      "type": "rectangle",
      "x": 630,
      "y": 730,
      "width": 250,
      "height": 100,
      "strokeColor": "#9c36b5",
      "backgroundColor": "#1a1a1a",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "roughness": 1,
      "opacity": 100,
      "groupIds": ["section2"]
    },
    {
      "id": "flow-sd-label",
      "type": "text",
      "x": 650,
      "y": 745,
      "width": 210,
      "height": 70,
      "fontSize": 16,
      "fontFamily": 1,
      "text": "Stable Diffusion\nDiffusion Process\n(50 steps)\n+ CLIP Guidance",
      "textAlign": "center",
      "verticalAlign": "top",
      "baseline": 63,
      "strokeColor": "#9c36b5",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section2"]
    },
    {
      "id": "arrow3",
      "type": "arrow",
      "x": 880,
      "y": 780,
      "width": 70,
      "height": 0,
      "strokeColor": "#f08c00",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 3,
      "roughness": 0,
      "opacity": 100,
      "startArrowhead": null,
      "endArrowhead": "arrow",
      "groupIds": ["section2"],
      "points": [[0, 0], [70, 0]]
    },
    {
      "id": "flow-output-img",
      "type": "rectangle",
      "x": 950,
      "y": 730,
      "width": 200,
      "height": 100,
      "strokeColor": "#1971c2",
      "backgroundColor": "#1a1a1a",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "roughness": 1,
      "opacity": 100,
      "groupIds": ["section2"]
    },
    {
      "id": "flow-output-img-label",
      "type": "text",
      "x": 970,
      "y": 755,
      "width": 160,
      "height": 50,
      "fontSize": 18,
      "fontFamily": 1,
      "text": "OUTPUT\n512√ó512\nImage",
      "textAlign": "center",
      "verticalAlign": "top",
      "baseline": 43,
      "strokeColor": "#1971c2",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section2"]
    },
    {
      "id": "arrow4-down",
      "type": "arrow",
      "x": 1050,
      "y": 830,
      "width": 0,
      "height": 60,
      "strokeColor": "#f08c00",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 3,
      "roughness": 0,
      "opacity": 100,
      "startArrowhead": null,
      "endArrowhead": "arrow",
      "groupIds": ["section2"],
      "points": [[0, 0], [0, 60]]
    },
    {
      "id": "flow-caption",
      "type": "rectangle",
      "x": 950,
      "y": 890,
      "width": 200,
      "height": 100,
      "strokeColor": "#2f9e44",
      "backgroundColor": "#1a1a1a",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "roughness": 1,
      "opacity": 100,
      "groupIds": ["section2"]
    },
    {
      "id": "flow-caption-label",
      "type": "text",
      "x": 970,
      "y": 905,
      "width": 160,
      "height": 70,
      "fontSize": 16,
      "fontFamily": 1,
      "text": "BLIP-2\nCaptioning\n(Beam Search)\n\n‚Üí Text caption",
      "textAlign": "center",
      "verticalAlign": "top",
      "baseline": 63,
      "strokeColor": "#2f9e44",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section2"]
    },
    {
      "id": "arrow5-left",
      "type": "arrow",
      "x": 950,
      "y": 780,
      "width": 180,
      "height": 100,
      "strokeColor": "#9c36b5",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "roughness": 0,
      "opacity": 100,
      "startArrowhead": null,
      "endArrowhead": "arrow",
      "groupIds": ["section2"],
      "points": [[0, 0], [-180, 100]],
      "strokeStyle": "dashed"
    },
    {
      "id": "flow-clip-img",
      "type": "rectangle",
      "x": 630,
      "y": 880,
      "width": 140,
      "height": 110,
      "strokeColor": "#9c36b5",
      "backgroundColor": "#1a1a1a",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "roughness": 1,
      "opacity": 100,
      "groupIds": ["section2"]
    },
    {
      "id": "flow-clip-img-label",
      "type": "text",
      "x": 650,
      "y": 905,
      "width": 100,
      "height": 60,
      "fontSize": 14,
      "fontFamily": 1,
      "text": "CLIP\nVision\nEncoder\n\n512-dim",
      "textAlign": "center",
      "verticalAlign": "top",
      "baseline": 53,
      "strokeColor": "#9c36b5",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section2"]
    },
    {
      "id": "arrow6-faiss",
      "type": "arrow",
      "x": 630,
      "y": 935,
      "width": 140,
      "height": 0,
      "strokeColor": "#f08c00",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 3,
      "roughness": 0,
      "opacity": 100,
      "startArrowhead": null,
      "endArrowhead": "arrow",
      "groupIds": ["section2"],
      "points": [[0, 0], [-140, 0]]
    },
    {
      "id": "flow-faiss",
      "type": "rectangle",
      "x": 330,
      "y": 880,
      "width": 160,
      "height": 110,
      "strokeColor": "#e03131",
      "backgroundColor": "#1a1a1a",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "roughness": 1,
      "opacity": 100,
      "groupIds": ["section2"]
    },
    {
      "id": "flow-faiss-label",
      "type": "text",
      "x": 350,
      "y": 905,
      "width": 120,
      "height": 60,
      "fontSize": 14,
      "fontFamily": 1,
      "text": "FAISS\nVector DB\n\nTop-K\nSearch",
      "textAlign": "center",
      "verticalAlign": "top",
      "baseline": 53,
      "strokeColor": "#e03131",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section2"]
    },
    {
      "id": "arrow7-results",
      "type": "arrow",
      "x": 330,
      "y": 935,
      "width": 180,
      "height": 0,
      "strokeColor": "#f08c00",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 3,
      "roughness": 0,
      "opacity": 100,
      "startArrowhead": null,
      "endArrowhead": "arrow",
      "groupIds": ["section2"],
      "points": [[0, 0], [-180, 0]]
    },
    {
      "id": "flow-results",
      "type": "rectangle",
      "x": 70,
      "y": 880,
      "width": 160,
      "height": 110,
      "strokeColor": "#1971c2",
      "backgroundColor": "#1a1a1a",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "roughness": 1,
      "opacity": 100,
      "groupIds": ["section2"]
    },
    {
      "id": "flow-results-label",
      "type": "text",
      "x": 90,
      "y": 905,
      "width": 120,
      "height": 60,
      "fontSize": 14,
      "fontFamily": 1,
      "text": "Similar\nImages\n\nRecall@5\n‚â•70%",
      "textAlign": "center",
      "verticalAlign": "top",
      "baseline": 53,
      "strokeColor": "#1971c2",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section2"]
    },
    {
      "id": "flow-legend",
      "type": "rectangle",
      "x": 1200,
      "y": 730,
      "width": 390,
      "height": 260,
      "strokeColor": "#f08c00",
      "backgroundColor": "#2c2c2c",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "roughness": 1,
      "opacity": 100,
      "groupIds": ["section2"]
    },
    {
      "id": "flow-legend-title",
      "type": "text",
      "x": 1220,
      "y": 745,
      "width": 350,
      "height": 25,
      "fontSize": 20,
      "fontFamily": 1,
      "text": "üîÑ 4 Multi-Modal Workflows",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 18,
      "strokeColor": "#f08c00",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section2"]
    },
    {
      "id": "flow-legend-content",
      "type": "text",
      "x": 1220,
      "y": 780,
      "width": 350,
      "height": 195,
      "fontSize": 16,
      "fontFamily": 1,
      "text": "1Ô∏è‚É£ Text ‚Üí Image (Generation)\n   Text ‚Üí CLIP ‚Üí SD ‚Üí Image\n\n2Ô∏è‚É£ Image ‚Üí Text (Captioning)\n   Image ‚Üí BLIP-2 ‚Üí Caption\n\n3Ô∏è‚É£ Text ‚Üí Images (Search)\n   Query ‚Üí CLIP ‚Üí FAISS ‚Üí Results\n\n4Ô∏è‚É£ Image ‚Üí Images (Similar)\n   Image ‚Üí CLIP ‚Üí FAISS ‚Üí Similar\n\nAll share CLIP embedding space!",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 185,
      "strokeColor": "#ffffff",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section2"]
    },
    {
      "id": "section3-header",
      "type": "rectangle",
      "x": 50,
      "y": 1050,
      "width": 1800,
      "height": 50,
      "strokeColor": "#f08c00",
      "backgroundColor": "#2c2c2c",
      "fillStyle": "solid",
      "strokeWidth": 3,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section3"]
    },
    {
      "id": "section3-title",
      "type": "text",
      "x": 70,
      "y": 1062,
      "width": 1000,
      "height": 30,
      "fontSize": 24,
      "fontFamily": 1,
      "text": "3Ô∏è‚É£ KEY CONCEPTS: Multi-Modal Learning Techniques",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 21,
      "strokeColor": "#f08c00",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section3"]
    },
    {
      "id": "concept1",
      "type": "rectangle",
      "x": 70,
      "y": 1130,
      "width": 420,
      "height": 240,
      "strokeColor": "#1971c2",
      "backgroundColor": "#1a1a1a",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "roughness": 1,
      "opacity": 100,
      "groupIds": ["section3"]
    },
    {
      "id": "concept1-title",
      "type": "text",
      "x": 90,
      "y": 1145,
      "width": 380,
      "height": 30,
      "fontSize": 22,
      "fontFamily": 1,
      "text": "üéØ CLIP Contrastive Learning",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 21,
      "strokeColor": "#1971c2",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section3"]
    },
    {
      "id": "concept1-content",
      "type": "text",
      "x": 90,
      "y": 1185,
      "width": 380,
      "height": 170,
      "fontSize": 16,
      "fontFamily": 1,
      "text": "Dual Encoders:\n‚Ä¢ Vision: ViT (Vision Transformer)\n‚Ä¢ Text: Transformer (GPT-style)\n\nJoint Embedding Space:\n‚Ä¢ Both ‚Üí 512-dim vectors\n‚Ä¢ Normalized (L2 norm = 1)\n‚Ä¢ Cosine similarity matching\n\nContrastive Loss:\nMaximize: matching pairs (image, text)\nMinimize: non-matching pairs",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 160,
      "strokeColor": "#ffffff",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section3"]
    },
    {
      "id": "concept2",
      "type": "rectangle",
      "x": 520,
      "y": 1130,
      "width": 420,
      "height": 240,
      "strokeColor": "#2f9e44",
      "backgroundColor": "#1a1a1a",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "roughness": 1,
      "opacity": 100,
      "groupIds": ["section3"]
    },
    {
      "id": "concept2-title",
      "type": "text",
      "x": 540,
      "y": 1145,
      "width": 380,
      "height": 30,
      "fontSize": 22,
      "fontFamily": 1,
      "text": "üåä Latent Diffusion (Stable Diffusion)",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 21,
      "strokeColor": "#2f9e44",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section3"]
    },
    {
      "id": "concept2-content",
      "type": "text",
      "x": 540,
      "y": 1185,
      "width": 380,
      "height": 170,
      "fontSize": 16,
      "fontFamily": 1,
      "text": "Denoising Process:\n‚Ä¢ Start: Random noise (latent)\n‚Ä¢ Steps: 20-50 denoising iterations\n‚Ä¢ End: Clean image (512√ó512)\n\nText Conditioning:\n‚Ä¢ CLIP text embedding guides process\n‚Ä¢ Cross-attention at each layer\n\nGuidance Scale (7-15):\n‚Ä¢ Low ‚Üí creative, may ignore prompt\n‚Ä¢ High ‚Üí follows prompt closely",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 160,
      "strokeColor": "#ffffff",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section3"]
    },
    {
      "id": "concept3",
      "type": "rectangle",
      "x": 970,
      "y": 1130,
      "width": 420,
      "height": 240,
      "strokeColor": "#9c36b5",
      "backgroundColor": "#1a1a1a",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "roughness": 1,
      "opacity": 100,
      "groupIds": ["section3"]
    },
    {
      "id": "concept3-title",
      "type": "text",
      "x": 990,
      "y": 1145,
      "width": 380,
      "height": 30,
      "fontSize": 22,
      "fontFamily": 1,
      "text": "üí¨ Beam Search Decoding",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 21,
      "strokeColor": "#9c36b5",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section3"]
    },
    {
      "id": "concept3-content",
      "type": "text",
      "x": 990,
      "y": 1185,
      "width": 380,
      "height": 170,
      "fontSize": 16,
      "fontFamily": 1,
      "text": "BLIP-2 Captioning:\n‚Ä¢ Vision encoder ‚Üí image features\n‚Ä¢ Language decoder ‚Üí generate text\n‚Ä¢ Cross-attention fusion\n\nBeam Search (num_beams=5):\n‚Ä¢ Explore 5 parallel sequences\n‚Ä¢ Keep top-K at each step\n‚Ä¢ Better quality than greedy\n\nOutput: Descriptive 15-25 word caption\nTarget: BLEU-4 ‚â• 0.25",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 160,
      "strokeColor": "#ffffff",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section3"]
    },
    {
      "id": "concept4",
      "type": "rectangle",
      "x": 1420,
      "y": 1130,
      "width": 430,
      "height": 240,
      "strokeColor": "#e03131",
      "backgroundColor": "#1a1a1a",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "roughness": 1,
      "opacity": 100,
      "groupIds": ["section3"]
    },
    {
      "id": "concept4-title",
      "type": "text",
      "x": 1440,
      "y": 1145,
      "width": 390,
      "height": 30,
      "fontSize": 22,
      "fontFamily": 1,
      "text": "üîç FAISS Vector Similarity Search",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 21,
      "strokeColor": "#e03131",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section3"]
    },
    {
      "id": "concept4-content",
      "type": "text",
      "x": 1440,
      "y": 1185,
      "width": 390,
      "height": 170,
      "fontSize": 16,
      "fontFamily": 1,
      "text": "IndexFlatIP (Inner Product):\n‚Ä¢ Exact cosine similarity search\n‚Ä¢ For normalized vectors (L2=1)\n‚Ä¢ Efficient for <10K vectors\n\nWorkflow:\n1. Embed images with CLIP ‚Üí 512-dim\n2. Build FAISS index from embeddings\n3. Query: text or image ‚Üí CLIP embed\n4. Search: index.search(query, k=5)\n5. Return: Top-K similar items\n\nRecall@5: ‚â•70% on test queries",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 160,
      "strokeColor": "#ffffff",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section3"]
    },
    {
      "id": "section4-header",
      "type": "rectangle",
      "x": 50,
      "y": 1420,
      "width": 1800,
      "height": 50,
      "strokeColor": "#f08c00",
      "backgroundColor": "#2c2c2c",
      "fillStyle": "solid",
      "strokeWidth": 3,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section4"]
    },
    {
      "id": "section4-title",
      "type": "text",
      "x": 70,
      "y": 1432,
      "width": 800,
      "height": 30,
      "fontSize": 24,
      "fontFamily": 1,
      "text": "4Ô∏è‚É£ TIMELINE: Implementation Workflow (4 TODOs)",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 21,
      "strokeColor": "#f08c00",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section4"]
    },
    {
      "id": "timeline-base",
      "type": "line",
      "x": 70,
      "y": 1540,
      "width": 1730,
      "height": 0,
      "strokeColor": "#f08c00",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 4,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section4"],
      "points": [[0, 0], [1730, 0]]
    },
    {
      "id": "step0",
      "type": "ellipse",
      "x": 60,
      "y": 1525,
      "width": 30,
      "height": 30,
      "strokeColor": "#2f9e44",
      "backgroundColor": "#2f9e44",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section4"]
    },
    {
      "id": "step0-label",
      "type": "text",
      "x": 45,
      "y": 1565,
      "width": 180,
      "height": 90,
      "fontSize": 16,
      "fontFamily": 1,
      "text": "START\n‚úÖ Load Models\n(CLIP, SD, BLIP-2)\n\n100% Pre-built",
      "textAlign": "center",
      "verticalAlign": "top",
      "baseline": 83,
      "strokeColor": "#2f9e44",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section4"]
    },
    {
      "id": "step1",
      "type": "ellipse",
      "x": 380,
      "y": 1525,
      "width": 30,
      "height": 30,
      "strokeColor": "#9c36b5",
      "backgroundColor": "#9c36b5",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section4"]
    },
    {
      "id": "step1-label",
      "type": "text",
      "x": 305,
      "y": 1565,
      "width": 180,
      "height": 110,
      "fontSize": 16,
      "fontFamily": 1,
      "text": "TODO 1\nüî® CLIP Guidance\n\nAdd CLIP loss\nto diffusion\n\nDifficulty: MEDIUM",
      "textAlign": "center",
      "verticalAlign": "top",
      "baseline": 103,
      "strokeColor": "#9c36b5",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section4"]
    },
    {
      "id": "step2",
      "type": "ellipse",
      "x": 700,
      "y": 1525,
      "width": 30,
      "height": 30,
      "strokeColor": "#1971c2",
      "backgroundColor": "#1971c2",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section4"]
    },
    {
      "id": "step2-label",
      "type": "text",
      "x": 625,
      "y": 1565,
      "width": 180,
      "height": 110,
      "fontSize": 16,
      "fontFamily": 1,
      "text": "TODO 2\nüî® Beam Search\n\nImplement caption\ngeneration\n\nDifficulty: EASY",
      "textAlign": "center",
      "verticalAlign": "top",
      "baseline": 103,
      "strokeColor": "#1971c2",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section4"]
    },
    {
      "id": "step3",
      "type": "ellipse",
      "x": 1020,
      "y": 1525,
      "width": 30,
      "height": 30,
      "strokeColor": "#e03131",
      "backgroundColor": "#e03131",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section4"]
    },
    {
      "id": "step3-label",
      "type": "text",
      "x": 925,
      "y": 1565,
      "width": 220,
      "height": 110,
      "fontSize": 16,
      "fontFamily": 1,
      "text": "TODO 3\nüî® Retrieval System\n\nFAISS search +\nRecall@K metric\n\nDifficulty: MEDIUM",
      "textAlign": "center",
      "verticalAlign": "top",
      "baseline": 103,
      "strokeColor": "#e03131",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section4"]
    },
    {
      "id": "step4",
      "type": "ellipse",
      "x": 1380,
      "y": 1525,
      "width": 30,
      "height": 30,
      "strokeColor": "#9c36b5",
      "backgroundColor": "#9c36b5",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section4"]
    },
    {
      "id": "step4-label",
      "type": "text",
      "x": 1285,
      "y": 1565,
      "width": 220,
      "height": 110,
      "fontSize": 16,
      "fontFamily": 1,
      "text": "TODO 4\nüî® Gradio Interface\n\n4 tabs + callbacks\nModel caching\n\nDifficulty: HARD",
      "textAlign": "center",
      "verticalAlign": "top",
      "baseline": 103,
      "strokeColor": "#9c36b5",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section4"]
    },
    {
      "id": "step5",
      "type": "ellipse",
      "x": 1740,
      "y": 1525,
      "width": 30,
      "height": 30,
      "strokeColor": "#2f9e44",
      "backgroundColor": "#2f9e44",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section4"]
    },
    {
      "id": "step5-label",
      "type": "text",
      "x": 1645,
      "y": 1565,
      "width": 220,
      "height": 110,
      "fontSize": 16,
      "fontFamily": 1,
      "text": "FINISH\n‚úÖ Integration Test\n‚úÖ Benchmarking\n‚úÖ Portfolio Demo\n\n100 Points!",
      "textAlign": "center",
      "verticalAlign": "top",
      "baseline": 103,
      "strokeColor": "#2f9e44",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section4"]
    },
    {
      "id": "timeline-note",
      "type": "rectangle",
      "x": 70,
      "y": 1720,
      "width": 1780,
      "height": 80,
      "strokeColor": "#f08c00",
      "backgroundColor": "#2c2c2c",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "roughness": 1,
      "opacity": 100,
      "groupIds": ["section4"]
    },
    {
      "id": "timeline-note-text",
      "type": "text",
      "x": 90,
      "y": 1735,
      "width": 1740,
      "height": 50,
      "fontSize": 16,
      "fontFamily": 1,
      "text": "‚è±Ô∏è Estimated Time: 2-3 weeks | 70% pre-built (models, utils, tests) + 30% student work (4 TODOs)\nüìä Grading: Functionality (40%) + Integration (30%) + UI/UX (20%) + Portfolio (10%) | Bonus: +30pts for extensions",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 43,
      "strokeColor": "#ffffff",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section4"]
    },
    {
      "id": "section5-header",
      "type": "rectangle",
      "x": 50,
      "y": 1860,
      "width": 1800,
      "height": 50,
      "strokeColor": "#f08c00",
      "backgroundColor": "#2c2c2c",
      "fillStyle": "solid",
      "strokeWidth": 3,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section5"]
    },
    {
      "id": "section5-title",
      "type": "text",
      "x": 70,
      "y": 1872,
      "width": 900,
      "height": 30,
      "fontSize": 24,
      "fontFamily": 1,
      "text": "5Ô∏è‚É£ COMMON ERRORS: Multi-Modal Pitfalls & Fixes",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 21,
      "strokeColor": "#f08c00",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section5"]
    },
    {
      "id": "error1",
      "type": "rectangle",
      "x": 70,
      "y": 1940,
      "width": 570,
      "height": 180,
      "strokeColor": "#e03131",
      "backgroundColor": "#1a1a1a",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "roughness": 1,
      "opacity": 100,
      "groupIds": ["section5"]
    },
    {
      "id": "error1-icon",
      "type": "text",
      "x": 90,
      "y": 1955,
      "width": 530,
      "height": 30,
      "fontSize": 20,
      "fontFamily": 1,
      "text": "‚ùå CUDA Out of Memory",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 21,
      "strokeColor": "#e03131",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section5"]
    },
    {
      "id": "error1-content",
      "type": "text",
      "x": 90,
      "y": 1995,
      "width": 530,
      "height": 110,
      "fontSize": 16,
      "fontFamily": 1,
      "text": "Problem: Loading 3 large models (7GB total)\n\nSolution:\n‚úÖ Use FP16: torch_dtype=torch.float16 (50% less)\n‚úÖ Enable attention slicing: sd_pipeline.enable_attention_slicing()\n‚úÖ Generate smaller images: height=384, width=384\n‚úÖ Clear cache: torch.cuda.empty_cache() between tasks",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 103,
      "strokeColor": "#ffffff",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section5"]
    },
    {
      "id": "error2",
      "type": "rectangle",
      "x": 670,
      "y": 1940,
      "width": 570,
      "height": 180,
      "strokeColor": "#e03131",
      "backgroundColor": "#1a1a1a",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "roughness": 1,
      "opacity": 100,
      "groupIds": ["section5"]
    },
    {
      "id": "error2-icon",
      "type": "text",
      "x": 690,
      "y": 1955,
      "width": 530,
      "height": 30,
      "fontSize": 20,
      "fontFamily": 1,
      "text": "‚ùå CLIP Guidance Artifacts",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 21,
      "strokeColor": "#e03131",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section5"]
    },
    {
      "id": "error2-content",
      "type": "text",
      "x": 690,
      "y": 1995,
      "width": 530,
      "height": 110,
      "fontSize": 16,
      "fontFamily": 1,
      "text": "Problem: CLIP weight too high ‚Üí unnatural images\n\nSolution:\n‚úÖ Start with clip_guidance_scale=0.1 (low)\n‚úÖ Gradually increase: 0.1 ‚Üí 0.2 ‚Üí 0.3\n‚úÖ Never exceed 0.5 (causes distortion)\n‚úÖ Normalize gradients before adding to latents\n‚úÖ Test with simple prompts first",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 103,
      "strokeColor": "#ffffff",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section5"]
    },
    {
      "id": "error3",
      "type": "rectangle",
      "x": 1270,
      "y": 1940,
      "width": 580,
      "height": 180,
      "strokeColor": "#e03131",
      "backgroundColor": "#1a1a1a",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "roughness": 1,
      "opacity": 100,
      "groupIds": ["section5"]
    },
    {
      "id": "error3-icon",
      "type": "text",
      "x": 1290,
      "y": 1955,
      "width": 540,
      "height": 30,
      "fontSize": 20,
      "fontFamily": 1,
      "text": "‚ùå Generic Captions (Too Short)",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 21,
      "strokeColor": "#e03131",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section5"]
    },
    {
      "id": "error3-content",
      "type": "text",
      "x": 1290,
      "y": 1995,
      "width": 540,
      "height": 110,
      "fontSize": 16,
      "fontFamily": 1,
      "text": "Problem: \"a dog\" instead of descriptive caption\n\nSolution:\n‚úÖ Increase beam width: num_beams=10 (vs. 5)\n‚úÖ Increase max_length: max_length=40 (vs. 20)\n‚úÖ Add length_penalty=1.0 (avoids too-short outputs)\n‚úÖ Use early_stopping=True (quality control)\n‚úÖ Compare: greedy vs. beam search side-by-side",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 103,
      "strokeColor": "#ffffff",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section5"]
    },
    {
      "id": "error4",
      "type": "rectangle",
      "x": 70,
      "y": 2150,
      "width": 570,
      "height": 180,
      "strokeColor": "#e03131",
      "backgroundColor": "#1a1a1a",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "roughness": 1,
      "opacity": 100,
      "groupIds": ["section5"]
    },
    {
      "id": "error4-icon",
      "type": "text",
      "x": 90,
      "y": 2165,
      "width": 530,
      "height": 30,
      "fontSize": 20,
      "fontFamily": 1,
      "text": "‚ùå FAISS Search Returns Irrelevant Results",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 21,
      "strokeColor": "#e03131",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section5"]
    },
    {
      "id": "error4-content",
      "type": "text",
      "x": 90,
      "y": 2205,
      "width": 530,
      "height": 110,
      "fontSize": 16,
      "fontFamily": 1,
      "text": "Problem: Embeddings not normalized ‚Üí wrong similarity\n\nSolution:\n‚úÖ Normalize ALL embeddings: embedding / np.linalg.norm()\n‚úÖ Use IndexFlatIP (inner product for normalized vecs)\n‚úÖ Check L2 norm = 1.0: np.linalg.norm(embedding)\n‚úÖ Ensure query and database use same normalization\n‚úÖ Verify cosine similarity range: 0 to 1",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 103,
      "strokeColor": "#ffffff",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section5"]
    },
    {
      "id": "error5",
      "type": "rectangle",
      "x": 670,
      "y": 2150,
      "width": 570,
      "height": 180,
      "strokeColor": "#e03131",
      "backgroundColor": "#1a1a1a",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "roughness": 1,
      "opacity": 100,
      "groupIds": ["section5"]
    },
    {
      "id": "error5-icon",
      "type": "text",
      "x": 690,
      "y": 2165,
      "width": 530,
      "height": 30,
      "fontSize": 20,
      "fontFamily": 1,
      "text": "‚ùå Gradio App Reloads Models Every Request",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 21,
      "strokeColor": "#e03131",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section5"]
    },
    {
      "id": "error5-content",
      "type": "text",
      "x": 690,
      "y": 2205,
      "width": 530,
      "height": 110,
      "fontSize": 16,
      "fontFamily": 1,
      "text": "Problem: Loading 7GB models every click = slow!\n\nSolution:\n‚úÖ Load models ONCE in global scope (before interface)\n‚úÖ Cache in global variables: models = load_all_models()\n‚úÖ Pass models as function arguments (don't reload)\n‚úÖ Use Gradio state for session persistence\n‚úÖ Verify: models load at startup, not per callback",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 103,
      "strokeColor": "#ffffff",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section5"]
    },
    {
      "id": "error6",
      "type": "rectangle",
      "x": 1270,
      "y": 2150,
      "width": 580,
      "height": 180,
      "strokeColor": "#e03131",
      "backgroundColor": "#1a1a1a",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "roughness": 1,
      "opacity": 100,
      "groupIds": ["section5"]
    },
    {
      "id": "error6-icon",
      "type": "text",
      "x": 1290,
      "y": 2165,
      "width": 540,
      "height": 30,
      "fontSize": 20,
      "fontFamily": 1,
      "text": "‚ùå Low Recall@5 (<50%)",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 21,
      "strokeColor": "#e03131",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section5"]
    },
    {
      "id": "error6-content",
      "type": "text",
      "x": 1290,
      "y": 2205,
      "width": 540,
      "height": 110,
      "fontSize": 16,
      "fontFamily": 1,
      "text": "Problem: Retrieval not finding relevant images\n\nSolution:\n‚úÖ Use better prompts: \"a photo of [object]\" template\n‚úÖ Ensure ground truth is correctly labeled\n‚úÖ Increase database size (more diverse images)\n‚úÖ Test with clear queries: \"beach sunset\" vs. \"nature\"\n‚úÖ Verify CLIP model quality: ViT-L/14 > ViT-B/32",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 103,
      "strokeColor": "#ffffff",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section5"]
    },
    {
      "id": "section6-header",
      "type": "rectangle",
      "x": 50,
      "y": 2380,
      "width": 1800,
      "height": 50,
      "strokeColor": "#f08c00",
      "backgroundColor": "#2c2c2c",
      "fillStyle": "solid",
      "strokeWidth": 3,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section6"]
    },
    {
      "id": "section6-title",
      "type": "text",
      "x": 70,
      "y": 2392,
      "width": 800,
      "height": 30,
      "fontSize": 24,
      "fontFamily": 1,
      "text": "6Ô∏è‚É£ DEBUG CHECKLIST: Step-by-Step Verification",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 21,
      "strokeColor": "#f08c00",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section6"]
    },
    {
      "id": "debug1",
      "type": "rectangle",
      "x": 70,
      "y": 2460,
      "width": 420,
      "height": 340,
      "strokeColor": "#1971c2",
      "backgroundColor": "#1a1a1a",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "roughness": 1,
      "opacity": 100,
      "groupIds": ["section6"]
    },
    {
      "id": "debug1-title",
      "type": "text",
      "x": 90,
      "y": 2475,
      "width": 380,
      "height": 30,
      "fontSize": 20,
      "fontFamily": 1,
      "text": "üîç TODO 1: CLIP Guidance Check",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 21,
      "strokeColor": "#1971c2",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section6"]
    },
    {
      "id": "debug1-content",
      "type": "text",
      "x": 90,
      "y": 2515,
      "width": 380,
      "height": 270,
      "fontSize": 16,
      "fontFamily": 1,
      "text": "Before Testing:\n‚òê CLIP text embedding shape: (1, 512)\n‚òê Embedding is normalized (L2=1)\n‚òê clip_guidance_scale in range 0.1-0.3\n\nDuring Generation:\n‚òê Callback runs at each step\n‚òê CLIP gradient computed correctly\n‚òê Gradient normalized before adding\n‚òê No NaN in latents\n\nAfter Generation:\n‚òê Image looks natural (no artifacts)\n‚òê CLIP score > 0.30\n‚òê Generation time < 30s\n‚òê Test complex prompt: \"red cube on blue sphere\"",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 263,
      "strokeColor": "#ffffff",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section6"]
    },
    {
      "id": "debug2",
      "type": "rectangle",
      "x": 520,
      "y": 2460,
      "width": 420,
      "height": 340,
      "strokeColor": "#2f9e44",
      "backgroundColor": "#1a1a1a",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "roughness": 1,
      "opacity": 100,
      "groupIds": ["section6"]
    },
    {
      "id": "debug2-title",
      "type": "text",
      "x": 540,
      "y": 2475,
      "width": 380,
      "height": 30,
      "fontSize": 20,
      "fontFamily": 1,
      "text": "üí¨ TODO 2: Captioning Check",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 21,
      "strokeColor": "#2f9e44",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section6"]
    },
    {
      "id": "debug2-content",
      "type": "text",
      "x": 540,
      "y": 2515,
      "width": 380,
      "height": 270,
      "fontSize": 16,
      "fontFamily": 1,
      "text": "Before Testing:\n‚òê BLIP-2 model loaded correctly\n‚òê Image preprocessed (PIL ‚Üí tensor)\n‚òê num_beams=5 (not 1)\n\nDuring Generation:\n‚òê Beam search runs (not greedy)\n‚òê max_length=30 set\n‚òê length_penalty=1.0\n‚òê early_stopping=True\n\nAfter Generation:\n‚òê Caption length: 15-25 words\n‚òê Caption is descriptive (not \"a dog\")\n‚òê BLEU-4 score ‚â• 0.25 (on test set)\n‚òê Inference time < 5s\n‚òê Compare: greedy vs. beam quality",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 263,
      "strokeColor": "#ffffff",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section6"]
    },
    {
      "id": "debug3",
      "type": "rectangle",
      "x": 970,
      "y": 2460,
      "width": 420,
      "height": 340,
      "strokeColor": "#9c36b5",
      "backgroundColor": "#1a1a1a",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "roughness": 1,
      "opacity": 100,
      "groupIds": ["section6"]
    },
    {
      "id": "debug3-title",
      "type": "text",
      "x": 990,
      "y": 2475,
      "width": 380,
      "height": 30,
      "fontSize": 20,
      "fontFamily": 1,
      "text": "üîé TODO 3: Retrieval Check",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 21,
      "strokeColor": "#9c36b5",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section6"]
    },
    {
      "id": "debug3-content",
      "type": "text",
      "x": 990,
      "y": 2515,
      "width": 380,
      "height": 270,
      "fontSize": 16,
      "fontFamily": 1,
      "text": "FAISS Index Setup:\n‚òê All embeddings normalized (L2=1)\n‚òê Index type: IndexFlatIP\n‚òê Index size matches database: index.ntotal\n‚òê Embeddings shape: (N, 512)\n\nSearch Function:\n‚òê Query embedding normalized\n‚òê Query shape: (1, 512)\n‚òê Search returns (distances, indices)\n‚òê Distances are cosine similarities (0-1)\n\nRecall@K Metric:\n‚òê Ground truth labels correct\n‚òê Retrieved indices valid (< database size)\n‚òê Recall@5 ‚â• 70%\n‚òê Search time < 1s for 1000 images",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 263,
      "strokeColor": "#ffffff",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section6"]
    },
    {
      "id": "debug4",
      "type": "rectangle",
      "x": 1420,
      "y": 2460,
      "width": 430,
      "height": 340,
      "strokeColor": "#e03131",
      "backgroundColor": "#1a1a1a",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "roughness": 1,
      "opacity": 100,
      "groupIds": ["section6"]
    },
    {
      "id": "debug4-title",
      "type": "text",
      "x": 1440,
      "y": 2475,
      "width": 390,
      "height": 30,
      "fontSize": 20,
      "fontFamily": 1,
      "text": "üåê TODO 4: Gradio Interface Check",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 21,
      "strokeColor": "#e03131",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section6"]
    },
    {
      "id": "debug4-content",
      "type": "text",
      "x": 1440,
      "y": 2515,
      "width": 390,
      "height": 270,
      "fontSize": 16,
      "fontFamily": 1,
      "text": "App Structure:\n‚òê Models load once at startup (not per request)\n‚òê 4 tabs exist: Generate, Caption, Search, Edit\n‚òê All UI components connected to callbacks\n‚òê Parameter sliders have correct ranges\n\nFunctionality:\n‚òê Tab 1: Text ‚Üí Image works\n‚òê Tab 2: Image ‚Üí Caption works\n‚òê Tab 3: Text/Image ‚Üí Search works\n‚òê Tab 4: (Bonus) Edit works\n\nPerformance:\n‚òê Inference < 5s per operation\n‚òê No model reloading between requests\n‚òê Error handling (try/except blocks)\n‚òê App launches: python app.py ‚Üí localhost:7860",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 263,
      "strokeColor": "#ffffff",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section6"]
    },
    {
      "id": "section7-header",
      "type": "rectangle",
      "x": 50,
      "y": 2860,
      "width": 1800,
      "height": 50,
      "strokeColor": "#f08c00",
      "backgroundColor": "#2c2c2c",
      "fillStyle": "solid",
      "strokeWidth": 3,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section7"]
    },
    {
      "id": "section7-title",
      "type": "text",
      "x": 70,
      "y": 2872,
      "width": 1200,
      "height": 30,
      "fontSize": 24,
      "fontFamily": 1,
      "text": "7Ô∏è‚É£ MENTAL MODEL: The Multi-Modal Artist",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 21,
      "strokeColor": "#f08c00",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 2,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section7"]
    },
    {
      "id": "mental-model-box",
      "type": "rectangle",
      "x": 70,
      "y": 2940,
      "width": 1780,
      "height": 480,
      "strokeColor": "#9c36b5",
      "backgroundColor": "#1a1a1a",
      "fillStyle": "solid",
      "strokeWidth": 3,
      "roughness": 1,
      "opacity": 100,
      "groupIds": ["section7"]
    },
    {
      "id": "mental-artist",
      "type": "text",
      "x": 110,
      "y": 2970,
      "width": 1700,
      "height": 420,
      "fontSize": 18,
      "fontFamily": 1,
      "text": "Think of your multi-modal system as a MULTI-TALENTED ARTIST who:\n\n1Ô∏è‚É£ UNDERSTANDS BOTH LANGUAGES (CLIP):\n   ‚Ä¢ Speaks \"Visual\" (images) and \"Written\" (text) fluently\n   ‚Ä¢ Translates both into a shared \"thought space\" (512-dim embeddings)\n   ‚Ä¢ Can compare thoughts: \"Is this picture what you described?\" (cosine similarity)\n\n2Ô∏è‚É£ PAINTS FROM DESCRIPTIONS (Stable Diffusion):\n   ‚Ä¢ Starts with random noise (like a blank canvas)\n   ‚Ä¢ Follows your instructions step-by-step (50 denoising iterations)\n   ‚Ä¢ Uses their visual understanding to stay on track (CLIP guidance)\n   ‚Ä¢ Result: A painting that matches your words\n\n3Ô∏è‚É£ DESCRIBES WHAT THEY SEE (BLIP-2 Captioning):\n   ‚Ä¢ Looks at a picture carefully (vision encoder)\n   ‚Ä¢ Thinks about what to say (cross-attention)\n   ‚Ä¢ Writes a detailed description (beam search - considering multiple word choices)\n   ‚Ä¢ Result: \"A golden retriever playing with a ball in a sunny park\"\n\n4Ô∏è‚É£ FINDS SIMILAR ARTWORKS (FAISS Retrieval):\n   ‚Ä¢ Has a mental catalog of thousands of artworks (vector database)\n   ‚Ä¢ When you describe something or show a picture, they instantly recall similar pieces\n   ‚Ä¢ Ranks them by relevance (cosine similarity scores)\n   ‚Ä¢ Shows you the top 5 matches in seconds\n\nThe MAGIC: All 4 skills share the same \"visual understanding\" foundation (CLIP embeddings),\nso the artist can seamlessly switch between creating, describing, and searching!",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 413,
      "strokeColor": "#ffffff",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section7"]
    },
    {
      "id": "final-note",
      "type": "rectangle",
      "x": 50,
      "y": 3470,
      "width": 1800,
      "height": 120,
      "strokeColor": "#2f9e44",
      "backgroundColor": "#2c2c2c",
      "fillStyle": "solid",
      "strokeWidth": 3,
      "roughness": 1,
      "opacity": 100,
      "groupIds": ["section7"]
    },
    {
      "id": "final-note-text",
      "type": "text",
      "x": 70,
      "y": 3490,
      "width": 1760,
      "height": 80,
      "fontSize": 18,
      "fontFamily": 1,
      "text": "üéì PROJECT OUTCOME: By completing this project, you'll build a production-ready multi-modal AI system\nintegrating 4 state-of-the-art models. This is the SAME technology powering:\n‚Ä¢ DALL-E & Midjourney (text-to-image) ‚Ä¢ GPT-4 Vision (image understanding) ‚Ä¢ Google Lens (visual search)\n\nPerfect for portfolios, resumes, and real-world AI applications! üöÄ",
      "textAlign": "left",
      "verticalAlign": "top",
      "baseline": 73,
      "strokeColor": "#ffffff",
      "backgroundColor": "transparent",
      "fillStyle": "solid",
      "strokeWidth": 1,
      "roughness": 0,
      "opacity": 100,
      "groupIds": ["section7"]
    }
  ],
  "appState": {
    "viewBackgroundColor": "#121212",
    "gridSize": 20
  },
  "files": {}
}
